#!/usr/bin/env python3
"""
æ£€æŸ¥ç‚¹ä¿å­˜ä¿®å¤éªŒè¯è„šæœ¬
å¿«é€Ÿæµ‹è¯•ä¿å­˜é€»è¾‘æ˜¯å¦èƒ½é¿å…NCCLè¶…æ—¶
"""

import os
import sys
import tempfile
import torch
import torch.distributed as dist
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è®¾ç½®NCCLç¯å¢ƒå˜é‡
os.environ.setdefault('NCCL_TIMEOUT', '1800')
os.environ.setdefault('NCCL_DEBUG', 'WARN')

def test_checkpoint_save():
    """æµ‹è¯•æ£€æŸ¥ç‚¹ä¿å­˜é€»è¾‘"""
    
    # åˆ›å»ºä¸´æ—¶é…ç½®
    config = {
        'training': {
            'max_steps': 15,  # çŸ­æµ‹è¯•
            'save_steps': 5,  # æ¯5æ­¥ä¿å­˜
            'logging_steps': 1,
            'warmup_steps': 2,
            'learning_rate': 1e-4,
            'batch_size': 2,
            'gradient_accumulation_steps': 1,
            'weight_decay': 0.1,
            'beta1': 0.9,
            'beta2': 0.95,
            'eps': 1e-6,
            'lr_scheduler': 'cosine',
            'min_lr_ratio': 0.1,
            'max_grad_norm': 1.0,
            'gradient_checkpointing': False,
            'fp16': False,
            'bf16': True,
            'load_balance_coeff': 0.05,
            'entropy_reg_coeff': 0.0003,
            'distill_coeff': 0.0,
            'distill_temperature': 4.0,
            'max_seq_length': 512,  # è¾ƒçŸ­åºåˆ—
            'save_total_limit': 2
        },
        'model': {
            'vocab_size': 50257,
            'hidden_size': 768,    # è¾ƒå°æ¨¡å‹
            'num_layers': 6,       # è¾ƒå°‘å±‚æ•°
            'num_heads': 12,
            'window_size': 256,
            'global_heads': 2,
            'gate_rank': 64,
            'max_position_embeddings': 2048,
            'srte_encoding': 'learnable',
            'srte_share_across_layers': True,
            'srte_factorized_rank': 64,
            'attention_type': 'local_global',
            'tie_word_embeddings': True,
            'use_alignment': True,
            'layer_norm_eps': 1e-5,
            'dropout': 0.1,
            'drop_branch_prob': 0.0,  # å…³é—­éšæœºæ€§
            'load_balance_coeff': 0.1,
            'entropy_reg_coeff': 1e-4,
            'use_cache': True,
            'pad_token_id': 50256,
            'bos_token_id': 50256,
            'eos_token_id': 50256
        },
        'data': {
            'data_mode': 'static',
            'train_data_paths': ['data/wikipedia/wiki_en/wiki_en_00000.jsonl'],
            'tokenizer_path': 'gpt2',
            'max_length': 512,
            'min_length': 50,
            'add_special_tokens': True,
            'num_workers': 0,
            'pin_memory': False,
            'prefetch_factor': 2
        },
        'curriculum': {
            'enabled': False
        },
        'device': {
            'use_gpu': True,
            'mixed_precision': 'bf16',
            'compile_model': False
        },
        'logging': {
            'log_level': 'INFO',
            'log_dir': 'logs/',
            'log_file': None,
            'log_format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            'log_interval': 10,
            'save_interval': 200,
            'output_dir': '/tmp/test_checkpoints/',  # æœ¬åœ°å­˜å‚¨
            'wandb': {'enabled': False}
        },
        'gate_monitor': {
            'enabled': False
        },
        'system': {
            'distributed': False,  # å•GPUæµ‹è¯•
            'use_deepspeed': False,  # å…ˆæµ‹è¯•PyTorchåŸç”Ÿ
            'compile_model': False
        }
    }
    
    # åˆ›å»ºä¸´æ—¶æ•°æ®
    with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as f:
        # å†™å…¥ä¸€äº›æµ‹è¯•æ•°æ®
        for i in range(100):
            f.write(f'{{"text": "This is test sentence {i} for checkpoint validation."}}\n')
        temp_data_path = f.name
    
    # æ›´æ–°æ•°æ®è·¯å¾„
    config['data']['train_data_paths'] = [temp_data_path]
    
    try:
        from train.engine import TrainingEngine
        
        print("ğŸ§ª Starting checkpoint save test...")
        print(f"  ğŸ“ Output dir: {config['logging']['output_dir']}")
        print(f"  ğŸ“Š Steps: {config['training']['max_steps']}")
        print(f"  ğŸ’¾ Save every: {config['training']['save_steps']} steps")
        
        # åˆ›å»ºè®­ç»ƒå¼•æ“
        engine = TrainingEngine(
            config=config,
            local_rank=0,
            rank=0,
            world_size=1
        )
        
        # è¿è¡ŒçŸ­æµ‹è¯•
        engine.train()
        
        print("âœ… Checkpoint save test completed successfully!")
        print("   No NCCL timeout issues detected.")
        
        # æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶
        output_dir = Path(config['logging']['output_dir'])
        if output_dir.exists():
            checkpoints = list(output_dir.glob('checkpoint_step_*'))
            print(f"   ğŸ“ Found {len(checkpoints)} checkpoints:")
            for ckpt in checkpoints:
                print(f"     - {ckpt.name}")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(temp_data_path)
        except:
            pass
    
    return True

def test_deepspeed_save():
    """æµ‹è¯•DeepSpeedä¿å­˜é€»è¾‘"""
    print("\nğŸ§ª Testing DeepSpeed save logic (single GPU)...")
    
    # ä¸´æ—¶ä¿®æ”¹é…ç½®ä¸ºDeepSpeed
    config = {
        'training': {
            'max_steps': 10,
            'save_steps': 5,
            'logging_steps': 1,
            'warmup_steps': 1,
            'learning_rate': 1e-4,
            'batch_size': 1,
            'gradient_accumulation_steps': 1,
            'weight_decay': 0.1,
            'beta1': 0.9,
            'beta2': 0.95,
            'eps': 1e-6,
            'lr_scheduler': 'cosine',
            'min_lr_ratio': 0.1,
            'max_grad_norm': 1.0,
            'gradient_checkpointing': False,
            'fp16': False,
            'bf16': True,
            'load_balance_coeff': 0.05,
            'entropy_reg_coeff': 0.0003,
            'distill_coeff': 0.0,
            'distill_temperature': 4.0,
            'max_seq_length': 256,
            'save_total_limit': 2
        },
        'model': {
            'vocab_size': 1000,     # æå°è¯æ±‡è¡¨
            'hidden_size': 256,     # æå°æ¨¡å‹
            'num_layers': 2,
            'num_heads': 4,
            'window_size': 128,
            'global_heads': 1,
            'gate_rank': 32,
            'max_position_embeddings': 512,
            'srte_encoding': 'learnable',
            'srte_share_across_layers': True,
            'srte_factorized_rank': 32,
            'attention_type': 'local_global',
            'tie_word_embeddings': True,
            'use_alignment': False,  # ç®€åŒ–
            'layer_norm_eps': 1e-5,
            'dropout': 0.0,
            'drop_branch_prob': 0.0,
            'load_balance_coeff': 0.1,
            'entropy_reg_coeff': 1e-4,
            'use_cache': True,
            'pad_token_id': 0,
            'bos_token_id': 0,
            'eos_token_id': 0
        },
        'data': {
            'data_mode': 'static',
            'tokenizer_path': 'gpt2',
            'max_length': 256,
            'min_length': 10,
            'add_special_tokens': True,
            'num_workers': 0,
            'pin_memory': False,
            'prefetch_factor': 2
        },
        'curriculum': {'enabled': False},
        'device': {
            'use_gpu': True,
            'mixed_precision': 'bf16',
            'compile_model': False
        },
        'logging': {
            'log_level': 'INFO',
            'log_dir': 'logs/',
            'output_dir': '/tmp/test_deepspeed_checkpoints/',
            'wandb': {'enabled': False}
        },
        'gate_monitor': {'enabled': False},
        'system': {
            'distributed': False,
            'use_deepspeed': True,
            'zero_stage': 2,
            'offload_optimizer': False,
            'offload_params': False,
            'compile_model': False
        }
    }
    
    # åˆ›å»ºæç®€æ•°æ®
    with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as f:
        for i in range(50):
            f.write(f'{{"text": "Test {i}"}}\n')
        temp_data_path = f.name
    
    config['data']['train_data_paths'] = [temp_data_path]
    
    try:
        from train.engine import TrainingEngine
        
        print(f"  ğŸ“ DeepSpeed output: {config['logging']['output_dir']}")
        
        engine = TrainingEngine(
            config=config,
            local_rank=0,
            rank=0,
            world_size=1
        )
        
        engine.train()
        print("âœ… DeepSpeed save test completed!")
        
    except Exception as e:
        print(f"âŒ DeepSpeed test failed: {e}")
        return False
    finally:
        try:
            os.unlink(temp_data_path)
        except:
            pass
    
    return True

if __name__ == "__main__":
    print("ğŸš€ Testing checkpoint save fixes...")
    
    success = True
    
    # æµ‹è¯•1ï¼šPyTorchåŸç”Ÿä¿å­˜
    if not test_checkpoint_save():
        success = False
    
    # æµ‹è¯•2ï¼šDeepSpeedä¿å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        import deepspeed
        if not test_deepspeed_save():
            success = False
    except ImportError:
        print("âš ï¸ DeepSpeed not available, skipping DeepSpeed test")
    
    if success:
        print("\nğŸ‰ All checkpoint save tests passed!")
        print("   The NCCL timeout fix should work correctly.")
    else:
        print("\nâŒ Some tests failed!")
        sys.exit(1) 