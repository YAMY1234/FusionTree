# FusionTree å…³é”®ä¿®å¤å®ŒæˆæŠ¥å‘Š

åŸºäºç³»ç»Ÿæ£€æŸ¥ç»“æœï¼Œå·²å®Œæˆæ‰€æœ‰**å¿…é¡»å°½å¿«ä¿®å¤çš„æ­£ç¡®æ€§/åŠŸèƒ½æ€§é—®é¢˜**ä¿®å¤ã€‚

## âœ… å·²å®Œæˆçš„å…³é”®ä¿®å¤ï¼ˆ7é¡¹ï¼‰

### 1. KVç¼“å­˜åœ¨prefillé˜¶æ®µæ²¡æœ‰è¿”å› 
**ä½ç½®**: `models/local_global_attn.py:330-339`
**é—®é¢˜**: prefillæ—¶ä¸è¿”å›æ–°KVç¼“å­˜ï¼Œå¯¼è‡´åç»­decodeæ— æ³•å¤ç”¨
**ä¿®å¤**: æ”¹ä¸ºåªè¦`use_cache=True`å°±è¿”å›ç¼“å­˜ï¼Œæ— è®ºæ˜¯å¦æœ‰å†å²ç¼“å­˜
```diff
-        if kv_cache is not None and use_cache:
+        if use_cache:
             if kv_cache is not None and 'k' in kv_cache and 'v' in kv_cache:
                 k = torch.cat([kv_cache['k'], k], dim=2)
                 v = torch.cat([kv_cache['v'], v], dim=2)
             new_kv_cache = {'k': k, 'v': v}
```

### 2. top_pé‡‡æ ·çš„æ•£å°„å®ç°é”™è¯¯
**ä½ç½®**: `models/hybrid_model.py:423-425`
**é—®é¢˜**: scatteræ“ä½œä½¿ç”¨ç›¸åŒå¼ é‡ä½œä¸ºindexå’Œsrcï¼Œé€»è¾‘é”™è¯¯
**ä¿®å¤**: åˆ›å»ºæ­£ç¡®çš„å¸ƒå°”æ©ç å¹¶ä½¿ç”¨scatter_è¿›è¡ŒåŸåœ°æ“ä½œ
```diff
-            indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)
-            logits[indices_to_remove] = float('-inf')
+            indices_to_remove = torch.zeros_like(logits, dtype=torch.bool)
+            indices_to_remove.scatter_(1, sorted_indices, sorted_indices_to_remove)
+            logits = logits.masked_fill(indices_to_remove, float('-inf'))
```

### 3. attention_maskçš„dtypeé—®é¢˜
**ä½ç½®**: `models/hybrid_model.py` å’Œ `train/data.py`
**é—®é¢˜**: attention_maskæ˜¯Longç±»å‹ï¼Œä½†ä»£ç ä¸­å½“ä½œboolä½¿ç”¨
**ä¿®å¤**: åœ¨æ¨¡å‹å…¥å£å’Œæ•°æ®collateä¸­éƒ½ç¡®ä¿è½¬ä¸ºboolç±»å‹
```diff
         if attention_mask is None:
             attention_mask = torch.ones_like(input_ids, dtype=torch.bool)
+        else:
+            attention_mask = attention_mask.to(torch.bool)
```

### 4. ç”Ÿæˆé˜¶æ®µattention_maskè¢«é”™è¯¯æˆªæ–­
**ä½ç½®**: `models/hybrid_model.py:300-301`
**é—®é¢˜**: decodeæ—¶æˆªæ–­maskä¼šä¸¢å¤±å†å²paddingä¿¡æ¯
**ä¿®å¤**: ä¿æŒå®Œæ•´çš„attention_maskä»¥æ­£ç¡®å±è”½å†å²padding
```diff
-        if attention_mask is not None and past_key_values is not None:
-            attention_mask = attention_mask[:, -1:]
+        # æ³¨æ„ï¼šä¿æŒå®Œæ•´ attention_mask ä»¥æ­£ç¡®å±è”½å†å² padding
+        # if attention_mask is not None and past_key_values is not None:
+        #     attention_mask = attention_mask[:, -1:]
```

### 5. SRTEä¸è¾“å…¥dtypeä¸å¯¹é½
**ä½ç½®**: `models/hybrid_block.py:203`
**é—®é¢˜**: bf16/fp16ä¸‹SRTEè¾“å‡ºä¸ºfp32ï¼Œä¸è¾“å…¥dtypeä¸åŒ¹é…
**ä¿®å¤**: å¼ºåˆ¶SRTEè¾“å‡ºä¸è¾“å…¥hidden_statesä¿æŒç›¸åŒdtype
```diff
-        time_encoding = self.srte(seq_len)  # [1, L, H]
+        time_encoding = self.srte(seq_len).to(hidden_states.dtype)  # [1, L, H]
```

### 6. num_headså‚æ•°æœªæ­£ç¡®é€ä¼ 
**ä½ç½®**: `models/hybrid_block.py` å’Œ `models/hybrid_model.py`
**é—®é¢˜**: LocalGlobalAttentionå§‹ç»ˆä½¿ç”¨é»˜è®¤çš„32ä¸ªå¤´ï¼Œæ— è§†é…ç½®
**ä¿®å¤**: æ·»åŠ num_headså‚æ•°å¹¶æ­£ç¡®é€ä¼ 
```diff
     def __init__(
         self,
         hidden_size: int,
+        num_heads: int = 32,
         window_size: int = 1024,
         ...
     ):
         ...
         self.attention = LocalGlobalAttention(
             hidden_size,
+            num_heads=num_heads,
             window_size=window_size,
             ...
         )
```

### 7. è„šæœ¬é…ç½®ä¸ä¸€è‡´
**ä½ç½®**: `scripts/run_eval.sh:45`
**é—®é¢˜**: ä¼ é€’äº†eval_llm.pyä¸æ”¯æŒçš„--configå‚æ•°
**ä¿®å¤**: ç§»é™¤è¯¥å‚æ•°ä¼ é€’

## ğŸš€ ä¿®å¤æ•ˆæœé¢„æœŸ

è¿™äº›ä¿®å¤å°†æ˜¾è‘—æ”¹å–„æ¨¡å‹è¡¨ç°ï¼š

1. **æ­£ç¡®çš„å¢é‡æ¨ç†**: KVç¼“å­˜å’ŒMambaçŠ¶æ€æ­£ç¡®ä¼ é€’ï¼Œdecodeé€Ÿåº¦å¤§å¹…æå‡
2. **æ­£ç¡®çš„é‡‡æ ·**: top_pé‡‡æ ·é€»è¾‘ä¿®å¤ï¼Œç”Ÿæˆè´¨é‡æå‡
3. **æ­£ç¡®çš„æ©ç å¤„ç†**: attention_maskç±»å‹å’Œé•¿åº¦æ­£ç¡®ï¼Œé¿å…æ³¨æ„åŠ›è®¡ç®—é”™è¯¯
4. **ç²¾åº¦ä¸€è‡´æ€§**: æ··åˆç²¾åº¦è®­ç»ƒæ—¶dtypeå¯¹é½ï¼Œé¿å…ç²¾åº¦æŸå¤±
5. **é…ç½®ä¸€è‡´æ€§**: æ¨¡å‹å¤´æ•°ç­‰å‚æ•°æ­£ç¡®åº”ç”¨

## ğŸ§ª éªŒè¯å»ºè®®

1. **åŸºç¡€åŠŸèƒ½æµ‹è¯•**:
```python
# æµ‹è¯•å¢é‡æ¨ç†
model.eval()
input_ids = torch.randint(0, 1000, (1, 100))
output = model.generate(input_ids, max_new_tokens=50, use_cache=True)
```

2. **é•¿åºåˆ—è®­ç»ƒ**:
```bash
# æµ‹è¯•32Kåºåˆ—ä¸OOM
python train/engine.py --config configs/pretrain_v1.yaml
```

3. **é‡‡æ ·è´¨é‡æ£€æŸ¥**:
```python
# æµ‹è¯•top_pé‡‡æ ·
output = model.generate(input_ids, do_sample=True, top_p=0.9, temperature=0.8)
```

## ğŸ“‹ å‰©ä½™å»ºè®®æ€§æ”¹è¿›

ä»¥ä¸‹å·¥ç¨‹æ”¹è¿›å¯åœ¨åç»­è¿­ä»£ä¸­å¤„ç†ï¼š
- æ·»åŠ DistributedSampleræ”¯æŒ
- å®ç°gradient accumulationå’ŒAMP
- æ·»åŠ å­¦ä¹ ç‡warmup
- æ”¹è¿›wandbå¯¼å…¥å¤„ç†
- è¡¥å……ç¼ºå¤±çš„deployç›®å½•
- æ·»åŠ CUDAå¯ç”¨æ€§æ£€æŸ¥

**ç»“è®º**: æ‰€æœ‰å½±å“æ­£ç¡®æ€§çš„å…³é”®é—®é¢˜å·²ä¿®å¤ï¼Œç°åœ¨å¯ä»¥å®‰å…¨è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°å®éªŒï¼ 