# HybridLanguageModel Wikipediaæµ‹è¯•é…ç½®
# å‡å°‘æ˜¾å­˜ä½¿ç”¨ï¼Œæµ‹è¯•ä¿å­˜åŠŸèƒ½
# åŸºäº pretrain_wikipedia.yaml è°ƒæ•´

training:
  max_steps: 100           # ğŸ§ª å‡å°‘åˆ°100æ­¥ç”¨äºæµ‹è¯•
  warmup_steps: 10         # å¯¹åº”å‡å°‘çƒ­èº«æ­¥æ•°
  learning_rate: 0.0001
  batch_size: 2            # ğŸ”§ ä»4é™åˆ°2ï¼Œå‡å°‘æ˜¾å­˜ä½¿ç”¨
  gradient_accumulation_steps: 4   # ğŸ”§ ä»2å¢åˆ°4ï¼Œä¿æŒæ€»batch sizeä¸å˜
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95
  eps: 0.000001
  
  # å­¦ä¹ ç‡è°ƒåº¦
  lr_scheduler: "cosine"
  min_lr_ratio: 0.1
  
  # æ¢¯åº¦ç›¸å…³
  max_grad_norm: 1.0
  gradient_checkpointing: true
  
  # æ··åˆç²¾åº¦
  fp16: false
  bf16: true
  
  # æ­£åˆ™åŒ–ç³»æ•°
  load_balance_coeff: 0.05
  entropy_reg_coeff: 0.0003
  distill_coeff: 0.0
  distill_temperature: 4.0
  
  # æ•°æ®ç›¸å…³
  max_seq_length: 512      # ğŸ”§ ä»1024é™åˆ°512ï¼Œå‡å°‘æ˜¾å­˜ä½¿ç”¨
  
  # ä¿å­˜å’Œè¯„ä¼° - ğŸ§ª æ›´é¢‘ç¹ä¿å­˜æµ‹è¯•checkpointåŠŸèƒ½
  save_steps: 20           # ğŸ”§ æ¯20æ­¥ä¿å­˜ä¸€æ¬¡ï¼Œæµ‹è¯•ä¿å­˜åŠŸèƒ½
  eval_steps: 20           # å¯¹åº”è°ƒæ•´è¯„ä¼°é¢‘ç‡
  logging_steps: 5         # æ›´é¢‘ç¹çš„æ—¥å¿—è¾“å‡º
  save_total_limit: 5      # ä¿ç•™æ›´å¤šcheckpointç”¨äºæµ‹è¯•

model:
  # ğŸ”§ å‡å°æ¨¡å‹å°ºå¯¸ä»¥é€‚åº”æ˜¾å­˜é™åˆ¶
  vocab_size: 50257
  hidden_size: 1024        # ğŸ”§ ä»1536é™åˆ°1024
  num_layers: 12           # ğŸ”§ ä»18é™åˆ°12
  num_heads: 8             # ğŸ”§ ä»12é™åˆ°8ï¼Œé€‚é…1024ç»´åº¦
  window_size: 128         # ğŸ”§ ä»256é™åˆ°128
  global_heads: 2
  gate_rank: 64            # ğŸ”§ ä»96é™åˆ°64
  max_position_embeddings: 4096   # ğŸ”§ ä»8192é™åˆ°4096
  
  # SRTEé…ç½®
  srte_encoding: "learnable"
  srte_share_across_layers: true
  srte_factorized_rank: 64         # ğŸ”§ ä»128é™åˆ°64ï¼Œå‡å°‘å‚æ•°é‡
  
  # æ³¨æ„åŠ›é…ç½®
  attention_type: "local_global"
  
  # å…¶ä»–ä¼˜åŒ–
  tie_word_embeddings: true
  use_alignment: true
  
  # æ­£åˆ™åŒ–
  layer_norm_eps: 0.00001
  dropout: 0.1
  drop_branch_prob: 0.1
  
  # æŸå¤±å‡½æ•°æƒé‡
  load_balance_coeff: 0.1
  entropy_reg_coeff: 0.0001
  
  # æ¨ç†é…ç½®
  use_cache: true
  pad_token_id: 50256
  bos_token_id: 50256
  eos_token_id: 50256

data:
  # æ•°æ®é…ç½®
  data_mode: lazy
  max_samples_per_file: 500   # ğŸ”§ å‡å°‘æ ·æœ¬æ•°é‡åŠ å¿«æµ‹è¯•
  
  train_data_paths:
    - "data/wikipedia/wiki_en/wiki_en_00000.jsonl"  # ğŸ”§ åªç”¨ä¸€ä¸ªæ–‡ä»¶æµ‹è¯•
  
  eval_data_paths:
    longbench:
      - "data/wikipedia/wiki_en/wiki_en_00000.jsonl"
  
  # é¢„å¤„ç†é…ç½®
  tokenizer_path: "gpt2"
  max_length: 512            # ğŸ”§ åŒ¹é…training.max_seq_length
  min_length: 50
  add_special_tokens: true
  
  # æ•°æ®åŠ è½½
  num_workers: 0
  pin_memory: true
  prefetch_factor: 2

# é•¿åº¦è¯¾ç¨‹å­¦ä¹  - ç¦ç”¨
curriculum:
  enabled: false
  
device:
  # è®¾å¤‡é…ç½®
  use_gpu: true
  mixed_precision: "bf16"
  compile_model: false

logging:
  # æ—¥å¿—é…ç½®
  log_level: "INFO"
  log_dir: "logs/"
  log_file: null
  log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_interval: 5           # æ›´é¢‘ç¹çš„æ—¥å¿—
  save_interval: 20         # åŒ¹é…save_steps
  output_dir: "/tmp/checkpoints/wikipedia_test/"  # ğŸ”§ ä¸“é—¨çš„æµ‹è¯•ç›®å½•
  
  # Wandbé…ç½®
  wandb:
    enabled: false
    project: "fusion-tree-test"
    name: "wikipedia-test"
    tags: ["test", "memory-optimized", "checkpoint-test"]

# é—¨æ§ç›‘æ§é…ç½®
gate_monitor:
  enabled: false

# ç³»ç»Ÿé…ç½®
system:
  # åˆ†å¸ƒå¼è®­ç»ƒ
  distributed: true
  backend: "nccl"
  find_unused_parameters: false
  
  # å†…å­˜ä¼˜åŒ– - ğŸ”§ å¯ç”¨æ›´æ¿€è¿›çš„å†…å­˜ä¼˜åŒ–
  use_deepspeed: true
  zero_stage: 3              # ğŸ”§ ä½¿ç”¨ZeRO-3è·å¾—æœ€å¤§å†…å­˜èŠ‚çœ
  offload_optimizer: true    # ğŸ”§ å¯ç”¨ä¼˜åŒ–å™¨offloadè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜
  offload_params: true       # ğŸ”§ å¯ç”¨å‚æ•°offload
  
  # ç¼–è¯‘ä¼˜åŒ–
  compile_model: false

# æµ‹è¯•è¯´æ˜:
# è¿™ä¸ªé…ç½®ç”¨äºæµ‹è¯•ï¼š
# 1. DeepSpeed checkpointä¿å­˜åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
# 2. è¾ƒå°çš„æ¨¡å‹æ˜¯å¦èƒ½åœ¨å½“å‰GPUä¸Šè¿è¡Œ
# 3. æ›´é¢‘ç¹çš„ä¿å­˜æ˜¯å¦ä¼šå¯¼è‡´é—®é¢˜
#
# ä¸åŸé…ç½®çš„ä¸»è¦å·®å¼‚ï¼š
# - æ¨¡å‹å°ºå¯¸å‡å°çº¦50%
# - åºåˆ—é•¿åº¦å‡åŠ
# - batch_sizeå‡åŠä½†ä¿æŒæ€»batch tokensç›¸åŒ
# - å¯ç”¨ZeRO-3å’Œoffloadä»¥æœ€å¤§åŒ–å†…å­˜èŠ‚çœ
# - æ¯20æ­¥ä¿å­˜ä¸€æ¬¡checkpoint
# - æ€»è®­ç»ƒæ­¥æ•°å‡å°‘åˆ°100æ­¥ 